# 《数学之美》读书笔记(二)

## 信息指纹/密码

- e.g. MD5,SHA-1
- 主要用处: 判断集合是否相同
- 相似哈希：对一篇文章的词进行TF-IDF编码，每个词算一个信息指纹，对应位为0则减w，为1则加w，最后算出的对应位大于0则化为1，小于则化为0

- 公开密钥的产生
  - 假设明码为067097101115097114（caesar的ascii码)
  - 找两个大素数P，Q
    - N = P \* Q
    - M = (P - 1) \* (Q - 1)
  - 找一个和M互素的E
  - 找一个D，使（E\*D）% M == 1
  - 完成！E是公钥，D是私钥，N是公开的
- 加密（Y是密码）

$$Y = X^E\space mod\space N$$

- 解密

$$X = Y^D\space mod\space N$$

---

## 最大熵

需要对一个随机事件的概率分布进行预测时，我们的预测应该满足所有**已知条件**，而**对未知情况不做任何主观假设**

$$
P(d|x_1,x_2,...,x_i)=\frac{1}{Z(x_1,x_2,...,x_i)}\cdot e^{\sum \lambda_i\cdot(x_i,d)}
$$

其中$d$是要预测的值，$x_1,x_2$是i个信息，Z是归一化因子，保证概率之和为1，$\lambda$是训练的参数

- 训练:GIS(Generalized Iterative Scaling,通用迭代算法)
  1. 假定第0次迭代为等概率分布
  2. 用第n次迭代的模型估计每种信息特征在训练数据中的分布，根据差值调整参数
  3. 重复2.至收敛
  - 是一个典型的EM算法（Expectation Maximization)
  - 改进的算法：IIS（Improved  Iterative Scaling）

---

### 布隆过滤器

### 贝叶斯网络

### 条件随机场

---

## 维特比算法

> 图论，动态规划

$$
d(S,x_{i,m}) = min(\underbrace{d(S,x_{i-1,n})}_{last\space iteration}+\underbrace{d(x_{i,m},x_{i-1,n})}_{easy\space to \space solve})
$$

起点$S$到第$i$步，第$m$个节点的最短距离等于min『对上一步中的每个结点，min『已有的最短距离+此节点到当前步中各个节点的距离』』

---

## 期望最大化算法（EM）

- 步骤  
  1. 随机挑K个点（$c_1(0),c_2(0),...,c_K(0)$，K为要划分的类的个数），作为起始的中心
  2. 计算所有点到中心的距离，将点归到最近的中心代表的那一类
  3. 重新计算中心，最简单的方法就是计算平均值
  4. 重复2，3，至收敛

### 收敛的必然性

我们希望同一类各个点到中心的平均距离d小，不同类之间的评价距离D大，我们希望每次迭代d变小，D变大  
假设第i类中有$n_i$个点，点到中心的平均距离是$d_i$，那么
$$
d = (n_1\cdot d_1+n_2\cdot d_2+...+n_k\cdot d_k)/k
$$
假定第i类到第j类中心的距离为$D_{ij}$，并且考虑根据类里点的个数来加权平均，那么
$$
D=\displaystyle\sum_{i,j}\frac{D_{ij}n_i n_j}{n(n-1)}
$$
显然，我们易得d，D都是递减的  

### 局部最优/全局最优

如果我们的优化函数是凸函数则一定有全局最优（e.g.熵函数，欧式距离，而余弦距离不是）

---

EOF
